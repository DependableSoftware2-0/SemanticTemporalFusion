{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7b226da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db853305",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dd5dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import PCAM\n",
    "from torchvision.datasets import SBDataset\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "\n",
    "import classification_kornia_dataloader\n",
    "\n",
    "from pytorch_lightning import LightningModule\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "import uncertain_fusion\n",
    "import evidence_loss\n",
    "\n",
    "from torch.distributions.dirichlet import Dirichlet\n",
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "from kornia.augmentation import RandomVerticalFlip, RandomHorizontalFlip, RandomErasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6025e085",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Preprocess(torch.nn.Module):\n",
    "    \"\"\"Module to perform pre-process using Kornia on torch tensors.\"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    @torch.no_grad()  # disable gradients for effiency\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        x_tmp: np.ndarray = np.array(x)  # HxWxC\n",
    "        x_out: Tensor = image_to_tensor(x_tmp, keepdim=True)  # CxHxW\n",
    "        return x_out.float() / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcb53d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CM_FILE_NAME = 'cifar_cm.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a067a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvidentialUncertainFusionTTA(LightningModule):\n",
    "    def __init__(self, \n",
    "                 arch_name: str = 'mobilenet',\n",
    "                 dataset_name: str = ''):\n",
    "        super().__init__()\n",
    "        self.n_classes = 2\n",
    "        self.model = self.select_model(arch_name)\n",
    "        \n",
    "        self.preprocess = Preprocess()\n",
    "        self.transform = self.transforms = nn.Sequential(\n",
    "                                                RandomHorizontalFlip(p=0.50),\n",
    "                                                RandomVerticalFlip(p=0.50),\n",
    "                                                RandomErasing(p=0.5)\n",
    "                                            )\n",
    "        \n",
    "        #self.flip = RandomHorizontalFlip(p=1.0)#testtime augmentation\n",
    "        self.flip =  RandomVerticalFlip(p=1.)\n",
    "        \n",
    "        self.train_accuracy = torchmetrics.Accuracy()\n",
    "        self.val_accuracy = torchmetrics.Accuracy()\n",
    "        self.val_flip_accuracy = torchmetrics.Accuracy()\n",
    "        self.ds_fusion_accuracy = torchmetrics.Accuracy()\n",
    "        self.bayes_fusion_accuracy = torchmetrics.Accuracy()\n",
    "        self.dampster_fusion_accuracy = torchmetrics.Accuracy()\n",
    "        self.sum_fusion_accuracy = torchmetrics.Accuracy()\n",
    "        self.mean_fusion_accuracy = torchmetrics.Accuracy()\n",
    "        \n",
    "        \n",
    "        self.train_cm = torchmetrics.ConfusionMatrix(num_classes=self.n_classes, normalize='true')\n",
    "        self.valid_cm = torchmetrics.ConfusionMatrix(num_classes=self.n_classes)\n",
    "        \n",
    "        self.DS_combine = uncertain_fusion.DempsterSchaferCombine(self.n_classes)\n",
    "        self.mean_combine = uncertain_fusion.MeanUncertainty(self.n_classes)\n",
    "        self.sum_combine = uncertain_fusion.SumUncertainty(self.n_classes)\n",
    "        \n",
    "        if os.path.isfile(CM_FILE_NAME): \n",
    "            cm = np.load(CM_FILE_NAME)\n",
    "            self.bayesian = uncertain_fusion.EffectiveProbability(confusion_matrix = cm)\n",
    "            self.dampster = uncertain_fusion.EffectiveProbability(confusion_matrix = cm, fusion_type='dampster')\n",
    "        else:\n",
    "            self.bayesian = None\n",
    "            self.dampster = None\n",
    "            \n",
    "        self.metric_data = []\n",
    "        \n",
    "        self.fusion_methods = [self.DS_combine, self.bayesian, self.mean_combine, self.sum_combine, self.dampster]\n",
    "        self.fusion_names = ['DS_combine',  'bayesian', 'mean', 'sum', 'destructive']\n",
    "        \n",
    "        self.fusion_accuracy = [self.ds_fusion_accuracy, \n",
    "                                self.bayes_fusion_accuracy,\n",
    "                                self.mean_fusion_accuracy,\n",
    "                                self.sum_fusion_accuracy,\n",
    "                                self.dampster_fusion_accuracy]\n",
    "        \n",
    "    def select_model(self, arch_name: str):\n",
    "        assert arch_name in [ 'mobilenet', 'resent' ]\n",
    "        \n",
    "        if arch_name == 'mobilenet':\n",
    "            model = torchvision.models.mobilenet_v3_small(weights=\"IMAGENET1K_V1\")\n",
    "            model.classifier = nn.Sequential(\n",
    "                                    nn.Linear(in_features=576, out_features=1024, bias=True),\n",
    "                                    nn.Hardswish(),\n",
    "                                    nn.Dropout(p=0.2, inplace=True),\n",
    "                                    nn.Linear(in_features=1024, out_features=self.n_classes, bias=True)\n",
    "                                  )\n",
    "        elif arch_name == 'resnet':\n",
    "            model = torchvision.models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "            model.fc = torch.nn.Linear(in_features=512, out_features=self.n_classes, bias=True)\n",
    "            \n",
    "        return model\n",
    "            \n",
    "            \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def compute_loss(self, y_hat, y):\n",
    "        y = F.one_hot(y, self.n_classes)\n",
    "        \n",
    "        # Predicted mask contains logits, and loss_fn param `from_logits` is set to True\n",
    "        loss = evidence_loss.edl_mse_loss(y_hat, y, self.current_epoch, self.n_classes, 10)\n",
    "   \n",
    "        #return F.cross_entropy(y_hat, y)\n",
    "        return loss\n",
    "\n",
    "    def show_batch(self, win_size=(10, 10)):\n",
    "        def _to_vis(data):\n",
    "            return tensor_to_image(torchvision.utils.make_grid(data, nrow=8))\n",
    "\n",
    "        # get a batch from the training set: try with `val_datlaoader` :)\n",
    "        imgs, labels = next(iter(self.train_dataloader()))\n",
    "        imgs_aug = self.transform(imgs)  # apply transforms\n",
    "        # use matplotlib to visualize\n",
    "        plt.figure(figsize=win_size)\n",
    "        plt.imshow(_to_vis(imgs))\n",
    "        plt.figure(figsize=win_size)\n",
    "        plt.imshow(_to_vis(imgs_aug))\n",
    "\n",
    "    def on_after_batch_transfer(self, batch, dataloader_idx):\n",
    "        x, y = batch\n",
    "        if self.trainer.training:\n",
    "            x = self.transform(x)  # => we perform GPU/Batched data augmentation\n",
    "        return x, y\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.compute_loss(y_hat, y)\n",
    "        self.train_accuracy.update(y_hat, y)\n",
    "        #self.log(\"train_loss\", loss, prog_bar=False)\n",
    "        self.log(\"train_acc\", self.train_accuracy, prog_bar=False)\n",
    "        self.logger.experiment.add_scalars('loss', {'train': loss}, self.global_step)\n",
    "        #self.logger.experiment.add_scalars('accuracy', {'train': self.train_accuracy}, self.global_step) \n",
    "        \n",
    "        y_hat = y_hat.argmax(dim=1, keepdim=True)\n",
    "        self.train_cm(y_hat, y)\n",
    "        return loss\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        np.save(CM_FILE_NAME, self.train_cm.compute().cpu().numpy())\n",
    "        self.train_cm.reset()\n",
    "    \n",
    "    def log_special(self, normalFusion, c_or_ic, name, t):\n",
    "        mean=torch.mean(torch.max(t, dim=1, keepdim=True).values).cpu().numpy().round(decimals=2)\n",
    "        median=torch.median(torch.max(t, dim=1, keepdim=True).values).cpu().numpy().round(decimals=2)\n",
    "        mean_prob=torch.mean(torch.max(t/torch.sum(t, dim=1, keepdim=True), \n",
    "                                            dim=1, keepdim=True).values).cpu().numpy().round(decimals=2)\n",
    "        median_prob=torch.median(torch.max(t/torch.sum(t, dim=1, keepdim=True), \n",
    "                                            dim=1, keepdim=True).values).cpu().numpy().round(decimals=2)\n",
    "        uncertain=torch.mean(self.n_classes/torch.sum(t, dim=1, keepdim=True)).cpu().numpy().round(decimals=2)\n",
    "        if mean > 1.0: #only dirchlet have greater than 1 \n",
    "            dirchlet = torch.mean(Dirichlet(t).entropy()).cpu().numpy().round(decimals=2)\n",
    "            categorical = torch.mean(Categorical(t/torch.sum(t, dim=1, keepdim=True)\n",
    "                                                    ).entropy()).cpu().numpy().round(decimals=2)\n",
    "            \n",
    "        else:\n",
    "            mean = 0.0\n",
    "            median = 0.0\n",
    "            dirchlet = 0.0\n",
    "            uncertain = 0.0\n",
    "            categorical = torch.mean(Categorical(t).entropy()).cpu().numpy().round(decimals=2)\n",
    "            \n",
    "        return [normalFusion, c_or_ic, name, mean, median, mean_prob, \n",
    "                median_prob, uncertain, dirchlet, categorical]\n",
    "        \n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.compute_loss(y_hat, y)\n",
    "        self.val_accuracy.update(y_hat, y)\n",
    "        #self.log(\"valid_loss\", loss, prog_bar=False)\n",
    "        #self.logger.experiment.add_scalars('loss', {'valid': loss}, self.global_step) \n",
    "        #self.logger.experiment.add_scalars('accuracy', {'valid': self.val_accuracy}, self.global_step) \n",
    "        self.log(\"valid_acc\", self.val_accuracy, prog_bar=True)\n",
    "                \n",
    "        #Uncertain fusion\n",
    "        #xflip = self.transform(imgs)\n",
    "        xflip = self.flip(x)\n",
    "        yflip_hat = F.relu(self(xflip)) + 1\n",
    "        self.val_flip_accuracy.update(yflip_hat, y)\n",
    "        self.log(\"valid_flip_acc\", self.val_flip_accuracy, prog_bar=True)\n",
    "        \n",
    "        y_hat = F.relu(y_hat) + 1\n",
    "        \n",
    "        #flipped image details\n",
    "        self.metric_data.append(self.log_special(\"normal\", \"all\", \"1\", yflip_hat))\n",
    "        y_max = yflip_hat.argmax(dim=1)\n",
    "        flip_correct_flags = (y_max == y)\n",
    "        self.metric_data.append(self.log_special(\"normal\", \"correct\", \"1\", yflip_hat[flip_correct_flags]))\n",
    "        self.metric_data.append(self.log_special(\"normal\", \"incorrect\", \"1\", yflip_hat[~flip_correct_flags]))\n",
    "        \n",
    "        #First frame\n",
    "        self.metric_data.append(self.log_special(\"normal\", \"all\", \"0\", y_hat))        \n",
    "        y_max = y_hat.argmax(dim=1)            \n",
    "        correct_flags = (y_max == y)\n",
    "        self.metric_data.append(self.log_special(\"normal\", \"correct\", \"0\", y_hat[correct_flags]))\n",
    "        self.metric_data.append(self.log_special(\"normal\", \"incorrect\", \"0\", y_hat[~correct_flags]))\n",
    "        \n",
    "        \n",
    "        \n",
    "        #for fusion, name, accuracy in zip([self.DS_combine, self.bayesian, self.dampster], \n",
    "        #                                  ['2 dampster', '3 bayesian', '4 destructive'], \n",
    "        #                                  [ self.ds_fusion_accuracy, self.bayes_fusion_accuracy, \n",
    "        #                                   self.dampster_fusion_accuracy]):\n",
    "        for fusion, name, accuracy in zip(self.fusion_methods, \n",
    "                                          self.fusion_names, \n",
    "                                          self.fusion_accuracy):\n",
    "            if None == fusion:\n",
    "                continue\n",
    "         \n",
    "            #fusion_out = fusion(y_hat, yflip_hat)\n",
    "            fusion_out = fusion(yflip_hat, y_hat)\n",
    "            fusion_out = fusion_out.to(self.device)\n",
    "            accuracy.update(fusion_out, y)\n",
    "            self.log(name+\"_fusion\", accuracy, prog_bar=True)\n",
    "            \n",
    "            self.metric_data.append(self.log_special('fuse', \"all\", name, fusion_out))\n",
    "                  \n",
    "            y_max = fusion_out.argmax(dim=1)\n",
    "            fused_correct_flags = (y_max == y)\n",
    "            self.metric_data.append(self.log_special('fuse', \"correct\", name, fusion_out[fused_correct_flags]))\n",
    "            self.metric_data.append(self.log_special('fuse', \"incorrect\", name, fusion_out[~fused_correct_flags]))\n",
    "            \n",
    "            #finding images which were wrong in first prediction and correct in fusion\n",
    "            c = fused_correct_flags & ~correct_flags & ~flip_correct_flags\n",
    "            \n",
    "            \n",
    "            #self.plot_changes(x[c], y[c], y_hat[c], yflip_hat[c], fusion_out[c], name)\n",
    "            \n",
    "        self.valid_cm(y_max, y)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def plot_changes(self, x, y, frame0, frame1, fused, fusion_name):\n",
    "        if (len(x)==0):\n",
    "            return\n",
    "        #fig = plt.figure(figsize=(5, 5))\n",
    "        fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "        title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "        \n",
    "        frame0 = frame0/torch.sum(frame0, dim=1, keepdim=True)\n",
    "        frame1 = frame1/torch.sum(frame1, dim=1, keepdim=True)\n",
    "        fused = fused/torch.sum(fused, dim=1, keepdim=True)\n",
    "        \n",
    "        both = torch.concat((frame0,frame1,fused), dim=1)\n",
    "        print (\"Total images\",len(x))\n",
    "        \n",
    "        \n",
    "\n",
    "        for i, (img, label, f) in enumerate(zip(x, y, both)):\n",
    "            plt.subplot(len(x),2, (i*2)+1)\n",
    "            plt.title(label.cpu().numpy())\n",
    "            plt.imshow(tensor_to_image(img))\n",
    "            plt.axis('off')\n",
    "            f=f.reshape(3,self.n_classes)\n",
    "            plt.subplot(len(x),2, (i*2)+2)\n",
    "            plt.title(fusion_name)\n",
    "            plt.imshow(tensor_to_image(f))\n",
    "            plt.axis('off')\n",
    "            \n",
    "        plt.show()    \n",
    "        # log figure\n",
    "        self.logger.experiment.add_figure('sample images', fig, global_step=self.global_step)\n",
    "    \n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        # turn confusion matrix into a figure (Tensor cannot be logged as a scalar)\n",
    "        fig, ax = plt.subplots(figsize=(20,20))\n",
    "        #plt.imshow(self.valid_cm.compute().cpu().numpy())\n",
    "        disp = ConfusionMatrixDisplay(self.valid_cm.compute().cpu().numpy())\n",
    "        disp.plot(ax=ax)\n",
    "        \n",
    "        # log figure\n",
    "        self.logger.experiment.add_figure('valid_epoch_confmat', fig, global_step=self.global_step)\n",
    "    \n",
    "        self.valid_cm.reset()\n",
    "        metrics = pd.DataFrame(self.metric_data, columns=['n', \n",
    "                                                          'c',\n",
    "                                                          'name',\n",
    "                                                          'mean', \n",
    "                                                          'median', \n",
    "                                                          'mean_prob', \n",
    "                                                          'median_prob', \n",
    "                                                          'uncertain',\n",
    "                                                          'dirchlet_entropy',\n",
    "                                                          'multinomial_entropy',])\n",
    "        self.metrics = metrics.groupby(['name','c'], as_index=False).mean().round(2)\n",
    "        \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=1e-2)\n",
    "        lr_scheduler = {\n",
    "            'scheduler': torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=1e-3, \n",
    "                                                       steps_per_epoch=len(self.train_dataloader()), \n",
    "                                                        epochs=self.trainer.max_epochs),\n",
    "            'name': 'oncyclelr',\n",
    "            'interval': 'step', # or 'epoch'\n",
    "            'frequency': 1\n",
    "        }\n",
    "        #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', verbose=True)\n",
    "        #scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
    "        #                                                       T_max=self.trainer.max_epochs, \n",
    "        #                                                      verbose=True)\n",
    "        #return [optimizer], [scheduler]\n",
    "        #return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"valid_acc\"}\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def prepare_data(self):\n",
    "        SBDataset(os.path.join(os.getcwd(), 'sbdataset/train'), 'train', download=True)\n",
    "        SBDataset(os.path.join(os.getcwd(), 'sbdataset/val'), 'val', download=True)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        \n",
    "        dataset = SBDataset(os.path.join(os.getcwd(), 'sbdataset/train'), 'train', download=True, \n",
    "                            transform=self.preprocess)\n",
    "        loader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=int(16/4))\n",
    "        return loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        \n",
    "        dataset = SBDataset(os.path.join(os.getcwd(), 'sbdataset/val'), 'val', download=True, \n",
    "                            transform=self.preprocess)\n",
    "        loader = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=int(16/4))\n",
    "        return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7f6c93b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/deebuls/Documents/phd/blender-dataset/SemanticTemporalFusion/semantic_segmentation_notebooks/sbdataset/train'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(os.getcwd(), 'sbdataset/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fdf3b5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EvidentialUncertainFusionTTA(arch_name='mobilenet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ca6e54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/semantic_contours/benchmark.tgz to /home/deebuls/Documents/phd/blender-dataset/SemanticTemporalFusion/semantic_segmentation_notebooks/sbdataset/train/benchmark.tgz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38487088b1eb4ee491c771e2a90946f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1419539633 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deebuls/miniconda3/envs/tpytorch/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:726: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "# Initialize a trainer\n",
    "trainer = Trainer(\n",
    "    #callbacks=[TQDMProgressBar(refresh_rate=20),\n",
    "    #           StochasticWeightAveraging(swa_lrs=1e-2)],\n",
    "    accelerator=\"auto\",\n",
    "    devices=1 if torch.cuda.is_available() else None,  # limiting got iPython runs\n",
    "    max_epochs=10,\n",
    "    callbacks=[LearningRateMonitor(logging_interval=\"step\"), TQDMProgressBar(refresh_rate=10)],\n",
    "    check_val_every_n_epoch = 20\n",
    ")\n",
    "\n",
    "trainer.fit(model)\n",
    "# Train the model ⚡\n",
    "trainer.validate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b402ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
